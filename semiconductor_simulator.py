"""
ë°˜ë„ì²´ ê³µì • í•™ìŠµ & ë©´ì ‘ ì‹œë®¬ë ˆì´í„°
í•™ë¶€ìƒì„ ìœ„í•œ ë§ì¶¤í˜• í•™ìŠµ ë° ë©´ì ‘ ì¤€ë¹„ í”Œë«í¼
"""

import os
import json
from typing import List, Dict, Optional
import gradio as gr
import azure.cognitiveservices.speech as speechsdk
from openai import AzureOpenAI
from azure.search.documents import SearchClient
from azure.search.documents.models import VectorizedQuery
from azure.core.credentials import AzureKeyCredential

from document_processor import SemiconductorDocumentProcessor
from resume_analyzer import ResumeAnalyzer


class SemiconductorSimulator:
    """ë°˜ë„ì²´ ê³µì • í•™ìŠµ/ë©´ì ‘ ì‹œë®¬ë ˆì´í„°"""
    
    def __init__(self):
        # Azure Speech Service
        self.speech_key = os.getenv("AZURE_SPEECH_KEY")
        self.speech_region = os.getenv("AZURE_SPEECH_REGION")
        self.custom_voice_name = os.getenv("CUSTOM_VOICE_NAME")
        
        # Azure OpenAI
        self.openai_client = AzureOpenAI(
            api_key=os.getenv("AZURE_OPENAI_KEY"),
            api_version="2024-02-15-preview",
            azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT")
        )
        self.gpt_deployment = os.getenv("GPT_DEPLOYMENT_NAME", "gpt-4")
        self.dalle_deployment = os.getenv("DALLE_DEPLOYMENT_NAME", "dall-e-3")
        
        # Azure AI Search
        self.search_client = SearchClient(
            endpoint=os.getenv("AZURE_SEARCH_ENDPOINT"),
            index_name="semiconductor-knowledge",
            credential=AzureKeyCredential(os.getenv("AZURE_SEARCH_KEY"))
        )
        
        # ë³´ì¡° ë„êµ¬
        self.doc_processor = SemiconductorDocumentProcessor()
        self.resume_analyzer = ResumeAnalyzer()
        
        # ì„¸ì…˜ ë°ì´í„°
        self.student_profile = None
        self.conversation_history = []
        self.current_question = None
        self.score_history = []
    
    def text_to_speech(self, text: str, output_file: str = "output.wav"):
        """Custom Voice TTS"""
        speech_config = speechsdk.SpeechConfig(
            subscription=self.speech_key,
            region=self.speech_region
        )
        speech_config.speech_synthesis_voice_name = self.custom_voice_name
        
        audio_config = speechsdk.audio.AudioOutputConfig(filename=output_file)
        synthesizer = speechsdk.SpeechSynthesizer(
            speech_config=speech_config,
            audio_config=audio_config
        )
        
        ssml = f"""
        <speak version='1.0' xmlns='http://www.w3.org/2001/10/synthesis' xml:lang='ko-KR'>
            <voice name='{self.custom_voice_name}'>
                <prosody rate='0.9' pitch='0%'>
                    {text}
                </prosody>
            </voice>
        </speak>
        """
        
        result = synthesizer.speak_ssml_async(ssml).get()
        
        if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:
            return output_file
        return None
    
    def speech_to_text(self, audio_file: str) -> str:
        """ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
        speech_config = speechsdk.SpeechConfig(
            subscription=self.speech_key,
            region=self.speech_region
        )
        speech_config.speech_recognition_language = "ko-KR"
        
        audio_config = speechsdk.audio.AudioConfig(filename=audio_file)
        recognizer = speechsdk.SpeechRecognizer(
            speech_config=speech_config,
            audio_config=audio_config
        )
        
        result = recognizer.recognize_once_async().get()
        
        if result.reason == speechsdk.ResultReason.RecognizedSpeech:
            return result.text
        return "ìŒì„± ì¸ì‹ ì‹¤íŒ¨"
    
    def get_embedding(self, text: str) -> List[float]:
        """í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±"""
        response = self.openai_client.embeddings.create(
            model="text-embedding-ada-002",
            input=text
        )
        return response.data[0].embedding
    
    def search_knowledge(
        self, 
        query: str, 
        process_filter: Optional[str] = None,
        difficulty_filter: Optional[str] = None,
        top_k: int = 5
    ) -> List[Dict]:
        """ë°˜ë„ì²´ ì§€ì‹ ê²€ìƒ‰"""
        try:
            query_vector = self.get_embedding(query)
            vector_query = VectorizedQuery(
                vector=query_vector,
                k_nearest_neighbors=top_k,
                fields="contentVector"
            )
            
            # í•„í„° êµ¬ì„±
            filter_expr = []
            if process_filter:
                filter_expr.append(f"process_category eq '{process_filter}'")
            if difficulty_filter:
                filter_expr.append(f"difficulty eq '{difficulty_filter}'")
            
            filter_str = " and ".join(filter_expr) if filter_expr else None
            
            results = self.search_client.search(
                search_text=query,
                vector_queries=[vector_query],
                filter=filter_str,
                select=["question", "answer", "process_category", "difficulty", "theory", "keywords"],
                top=top_k
            )
            
            return [
                {
                    "question": doc["question"],
                    "answer": doc.get("answer", ""),
                    "process_category": doc.get("process_category", ""),
                    "difficulty": doc.get("difficulty", ""),
                    "theory": doc.get("theory", ""),
                    "keywords": doc.get("keywords", [])
                }
                for doc in results
            ]
        except Exception as e:
            print(f"ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []
    
    def generate_study_question(
        self,
        topic: str,
        difficulty: str = "ì¤‘ê¸‰",
        question_type: str = "ê°œë…ì´í•´"
    ) -> Dict:
        """í•™ìŠµ ëª¨ë“œ - ì£¼ì œ ê¸°ë°˜ ì§ˆë¬¸ ìƒì„±"""
        # RAG ê²€ìƒ‰
        search_results = self.search_knowledge(
            query=topic,
            difficulty_filter=difficulty,
            top_k=3
        )
        
        context = "\n\n".join([
            f"ì°¸ê³  ì§ˆë¬¸ {i+1}:\n{q['question']}\në‹µë³€: {q['answer']}"
            for i, q in enumerate(search_results)
        ])
        
        prompt = f"""
ë°˜ë„ì²´ ê³µì • í•™ìŠµìš© ì§ˆë¬¸ì„ ìƒì„±í•˜ì„¸ìš”.

**ì£¼ì œ**: {topic}
**ë‚œì´ë„**: {difficulty}
**ì§ˆë¬¸ ìœ í˜•**: {question_type}

**ì°¸ê³  ìë£Œ**:
{context}

**ìš”êµ¬ì‚¬í•­**:
- í•™ë¶€ìƒ ìˆ˜ì¤€ì— ì í•©í•œ ì§ˆë¬¸
- ì´ë¡ ê³¼ ì‹¤ë¬´ë¥¼ ì—°ê²°í•˜ëŠ” ì§ˆë¬¸
- ëª…í™•í•œ í‰ê°€ ê¸°ì¤€

JSON í˜•ì‹:
{{
    "question": "ì§ˆë¬¸",
    "hint": "íŒíŠ¸ (ì„ íƒì )",
    "model_answer": "ëª¨ë²” ë‹µë³€",
    "evaluation_criteria": ["í‰ê°€ê¸°ì¤€1", "í‰ê°€ê¸°ì¤€2"],
    "related_concepts": ["ê´€ë ¨ê°œë…1", "ê´€ë ¨ê°œë…2"],
    "difficulty_explanation": "ì™œ ì´ ë‚œì´ë„ì¸ì§€"
}}
"""
        
        response = self.openai_client.chat.completions.create(
            model=self.gpt_deployment,
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ë°˜ë„ì²´ ê³µí•™ êµìˆ˜ì…ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            response_format={"type": "json_object"}
        )
        
        question_data = json.loads(response.choices[0].message.content)
        question_data['search_context'] = search_results
        
        return question_data
    
    def generate_interview_question(
        self,
        student_profile: Optional[Dict] = None,
        focus_area: Optional[str] = None
    ) -> Dict:
        """ë©´ì ‘ ëª¨ë“œ - ë§ì¶¤í˜• ì§ˆë¬¸ ìƒì„±"""
        if student_profile:
            # ê°œì¸ ë§ì¶¤í˜• ì§ˆë¬¸
            resume_data = student_profile.get('resume_analysis', {})
            statement_data = student_profile.get('statement_analysis', {})
            
            # ê´€ì‹¬ ë¶„ì•¼ ê¸°ë°˜ ê²€ìƒ‰
            interests = resume_data.get('interests', [])
            search_query = focus_area or (interests[0] if interests else "ë°˜ë„ì²´ ê³µì •")
            
            search_results = self.search_knowledge(search_query, top_k=3)
            
            context = f"""
**í•™ìƒ ì •ë³´**:
- ì „ê³µ: {resume_data.get('education', {}).get('major', 'N/A')}
- ê²½í—˜: {len(resume_data.get('semiconductor_experience', []))}ê±´
- ê´€ì‹¬ë¶„ì•¼: {', '.join(interests)}
- ëª©í‘œ: {statement_data.get('career_goals', {}).get('short_term', 'N/A')}

**ê²€ìƒ‰ëœ ê´€ë ¨ ì§ˆë¬¸**:
{chr(10).join([f"{i+1}. {q['question']}" for i, q in enumerate(search_results)])}
"""
            
            prompt = f"""
ë‹¤ìŒ í•™ìƒì—ê²Œ ì í•©í•œ ë©´ì ‘ ì§ˆë¬¸ì„ ìƒì„±í•˜ì„¸ìš”:

{context}

**ìš”êµ¬ì‚¬í•­**:
- í•™ìƒì˜ ê²½í—˜/ê´€ì‹¬ì‚¬ì™€ ì—°ê²°
- í•™ë¶€ìƒ ìˆ˜ì¤€ì— ì í•©
- êµ¬ì²´ì ì´ê³  í‰ê°€ ê°€ëŠ¥í•œ ì§ˆë¬¸

JSON í˜•ì‹:
{{
    "question": "ë©´ì ‘ ì§ˆë¬¸",
    "category": "ê³µì • ì¹´í…Œê³ ë¦¬",
    "personalization_reason": "ì´ í•™ìƒì—ê²Œ ì™œ ì í•©í•œì§€",
    "expected_points": ["ê¸°ëŒ€ë‹µë³€1", "ê¸°ëŒ€ë‹µë³€2"],
    "follow_ups": ["ì¶”ê°€ì§ˆë¬¸1", "ì¶”ê°€ì§ˆë¬¸2"]
}}
"""
        else:
            # ì¼ë°˜ ì§ˆë¬¸
            search_results = self.search_knowledge(
                focus_area or "ë°˜ë„ì²´ ê³µì •",
                top_k=3
            )
            
            prompt = f"""
ë°˜ë„ì²´ ê¸°ì—… ë©´ì ‘ ì§ˆë¬¸ì„ ìƒì„±í•˜ì„¸ìš”.

ì°¸ê³  ì§ˆë¬¸:
{chr(10).join([f"{i+1}. {q['question']}" for i, q in enumerate(search_results)])}

JSON í˜•ì‹:
{{
    "question": "ì§ˆë¬¸",
    "category": "ì¹´í…Œê³ ë¦¬",
    "model_answer": "ëª¨ë²”ë‹µë³€",
    "evaluation_points": ["í‰ê°€1", "í‰ê°€2"]
}}
"""
        
        response = self.openai_client.chat.completions.create(
            model=self.gpt_deployment,
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ë°˜ë„ì²´ ê¸°ì—… ë©´ì ‘ê´€ì…ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            response_format={"type": "json_object"}
        )
        
        question_data = json.loads(response.choices[0].message.content)
        question_data['search_context'] = search_results
        
        return question_data
    
    def evaluate_answer(
        self,
        question: str,
        student_answer: str,
        model_answer: str,
        context: List[Dict]
    ) -> Dict:
        """ë‹µë³€ í‰ê°€"""
        reference_context = "\n".join([
            f"ì°¸ê³  ë‹µë³€: {c.get('answer', '')}"
            for c in context
        ])
        
        prompt = f"""
í•™ìƒì˜ ë‹µë³€ì„ í‰ê°€í•˜ì„¸ìš”.

**ì§ˆë¬¸**: {question}

**í•™ìƒ ë‹µë³€**: {student_answer}

**ëª¨ë²” ë‹µë³€**: {model_answer}

**ì°¸ê³  ìë£Œ**:
{reference_context}

**í‰ê°€ ê¸°ì¤€**:
1. ì •í™•ì„± (30ì ): ê¸°ìˆ ì ìœ¼ë¡œ ì •í™•í•œê°€?
2. ê¹Šì´ (25ì ): ì›ë¦¬ë¥¼ ì´í•´í•˜ê³  ìˆëŠ”ê°€?
3. êµ¬ì¡° (20ì ): ë…¼ë¦¬ì ìœ¼ë¡œ ì„¤ëª…í•˜ëŠ”ê°€?
4. ì‘ìš© (15ì ): ì‹¤ë¬´/ì‹¤ìŠµê³¼ ì—°ê²°í•˜ëŠ”ê°€?
5. ì˜ì‚¬ì†Œí†µ (10ì ): ëª…í™•í•˜ê²Œ ì „ë‹¬í•˜ëŠ”ê°€?

JSON í˜•ì‹:
{{
    "total_score": 0-100,
    "breakdown": {{
        "accuracy": 0-30,
        "depth": 0-25,
        "structure": 0-20,
        "application": 0-15,
        "communication": 0-10
    }},
    "strengths": ["ê°•ì 1", "ê°•ì 2"],
    "improvements": ["ê°œì„ ì 1", "ê°œì„ ì 2"],
    "feedback": "ìƒì„¸ í”¼ë“œë°± (3-4ë¬¸ì¥)",
    "recommended_review": ["ë³µìŠµí•  ê°œë…1", "ë³µìŠµí•  ê°œë…2"]
}}
"""
        
        response = self.openai_client.chat.completions.create(
            model=self.gpt_deployment,
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ë°˜ë„ì²´ ê³µí•™ êµìˆ˜ì´ì í‰ê°€ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3,
            response_format={"type": "json_object"}
        )
        
        return json.loads(response.choices[0].message.content)
    
    def generate_process_diagram(self, process_name: str) -> Optional[str]:
        """ê³µì • ë‹¤ì´ì–´ê·¸ë¨ ìƒì„± (DALL-E)"""
        try:
            prompt = f"Technical diagram of {process_name} semiconductor fabrication process, cross-section view, labeled, educational style, clean and professional"
            
            result = self.openai_client.images.create(
                model=self.dalle_deployment,
                prompt=prompt,
                n=1,
                size="1024x1024"
            )
            
            return result.data[0].url
        except Exception as e:
            print(f"ì´ë¯¸ì§€ ìƒì„± ì˜¤ë¥˜: {e}")
            return None


def create_gradio_interface():
    """Gradio UI êµ¬ì„±"""
    simulator = SemiconductorSimulator()
    
    # ì„¸ì…˜ ìƒíƒœ
    class SessionState:
        def __init__(self):
            self.student_profile = None
            self.current_question = None
            self.question_count = 0
            self.score_history = []
            self.mode = "study"  # study or interview
    
    state = SessionState()
    
    # === í•¨ìˆ˜ ì •ì˜ ===
    
    def upload_and_analyze_documents(resume_file, statement_file):
        """ì´ë ¥ì„œ/ìì†Œì„œ ì—…ë¡œë“œ ë° ë¶„ì„"""
        if not resume_file and not statement_file:
            return "âŒ ìµœì†Œ í•˜ë‚˜ì˜ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.", ""
        
        try:
            profile = simulator.resume_analyzer.create_student_profile(
                resume_path=resume_file.name if resume_file else None,
                statement_path=statement_file.name if statement_file else None
            )
            
            state.student_profile = profile
            
            # í”„ë¡œí•„ ìš”ì•½
            summary = f"### âœ… í”„ë¡œí•„ ë¶„ì„ ì™„ë£Œ\n\n"
            summary += f"**ìš”ì•½**: {profile['summary']}\n\n"
            
            resume_data = profile.get('resume_analysis', {})
            if resume_data:
                summary += "**í•™ë ¥**:\n"
                edu = resume_data.get('education', {})
                summary += f"- {edu.get('major', 'N/A')} {edu.get('year', '')}í•™ë…„\n\n"
                
                summary += "**ë°˜ë„ì²´ ê²½í—˜**:\n"
                for exp in resume_data.get('semiconductor_experience', [])[:3]:
                    summary += f"- {exp.get('title', 'N/A')}\n"
                summary += "\n"
                
                summary += f"**ê´€ì‹¬ ë¶„ì•¼**: {', '.join(resume_data.get('interests', []))}\n\n"
            
            statement_data = profile.get('statement_analysis', {})
            if statement_data:
                summary += f"**ì»¤ë¦¬ì–´ ëª©í‘œ**: {statement_data.get('career_goals', {}).get('short_term', 'N/A')}\n\n"
            
            return summary, "âœ… ë§ì¶¤í˜• ì§ˆë¬¸ì„ ìƒì„±í•  ì¤€ë¹„ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤!"
        
        except Exception as e:
            return f"âŒ ì˜¤ë¥˜: {str(e)}", ""
    
    def start_study_mode(topic, difficulty, question_type):
        """í•™ìŠµ ëª¨ë“œ ì‹œì‘"""
        state.mode = "study"
        state.question_count += 1
        
        question_data = simulator.generate_study_question(
            topic=topic,
            difficulty=difficulty,
            question_type=question_type
        )
        
        state.current_question = question_data
        
        # TTS
        audio_file = f"study_q_{state.question_count}.wav"
        simulator.text_to_speech(question_data['question'], audio_file)
        
        # í™”ë©´ í‘œì‹œ
        display = f"### ğŸ“š í•™ìŠµ ì§ˆë¬¸ {state.question_count}\n\n"
        display += f"**ì£¼ì œ**: {topic}\n"
        display += f"**ë‚œì´ë„**: {difficulty}\n"
        display += f"**ìœ í˜•**: {question_type}\n\n"
        display += f"**ì§ˆë¬¸**: {question_data['question']}\n\n"
        
        if question_data.get('hint'):
            display += f"ğŸ’¡ *íŒíŠ¸*: {question_data['hint']}\n"
        
        return display, audio_file
    
    def start_interview_mode(focus_area, use_profile):
        """ë©´ì ‘ ëª¨ë“œ ì‹œì‘"""
        state.mode = "interview"
        state.question_count += 1
        
        profile = state.student_profile if use_profile else None
        
        question_data = simulator.generate_interview_question(
            student_profile=profile,
            focus_area=focus_area
        )
        
        state.current_question = question_data
        
        # TTS
        audio_file = f"interview_q_{state.question_count}.wav"
        simulator.text_to_speech(question_data['question'], audio_file)
        
        # í™”ë©´ í‘œì‹œ
        display = f"### ğŸ¯ ë©´ì ‘ ì§ˆë¬¸ {state.question_count}\n\n"
        display += f"**ì¹´í…Œê³ ë¦¬**: {question_data.get('category', 'N/A')}\n\n"
        display += f"**ì§ˆë¬¸**: {question_data['question']}\n\n"
        
        if question_data.get('personalization_reason'):
            display += f"*ğŸ“Œ ë§ì¶¤ ì´ìœ *: {question_data['personalization_reason']}\n"
        
        return display, audio_file
    
    def submit_answer(audio_input, text_input):
        """ë‹µë³€ ì œì¶œ ë° í‰ê°€"""
        # ë‹µë³€ ì¶”ì¶œ
        if audio_input:
            answer = simulator.speech_to_text(audio_input)
        else:
            answer = text_input
        
        if not answer or answer.strip() == "":
            return "âŒ ë‹µë³€ì„ ì…ë ¥í•˜ì„¸ìš”.", None, ""
        
        # í‰ê°€
        model_answer = state.current_question.get('model_answer', state.current_question.get('expected_points', [''])[0])
        
        evaluation = simulator.evaluate_answer(
            question=state.current_question['question'],
            student_answer=answer,
            model_answer=model_answer,
            context=state.current_question.get('search_context', [])
        )
        
        state.score_history.append(evaluation['total_score'])
        
        # í”¼ë“œë°± TTS
        feedback_text = f"ì ìˆ˜: {evaluation['total_score']}ì . {evaluation['feedback']}"
        feedback_audio = f"feedback_{state.question_count}.wav"
        simulator.text_to_speech(feedback_text, feedback_audio)
        
        # í™”ë©´ í‘œì‹œ
        result = f"### ğŸ“Š í‰ê°€ ê²°ê³¼\n\n"
        result += f"**ì´ì **: {evaluation['total_score']}/100\n\n"
        
        result += "**ì„¸ë¶€ ì ìˆ˜**:\n"
        breakdown = evaluation.get('breakdown', {})
        result += f"- ì •í™•ì„±: {breakdown.get('accuracy', 0)}/30\n"
        result += f"- ê¹Šì´: {breakdown.get('depth', 0)}/25\n"
        result += f"- êµ¬ì¡°: {breakdown.get('structure', 0)}/20\n"
        result += f"- ì‘ìš©: {breakdown.get('application', 0)}/15\n"
        result += f"- ì˜ì‚¬ì†Œí†µ: {breakdown.get('communication', 0)}/10\n\n"
        
        result += f"**ê°•ì **: {', '.join(evaluation.get('strengths', []))}\n\n"
        result += f"**ê°œì„ ì **: {', '.join(evaluation.get('improvements', []))}\n\n"
        result += f"**í”¼ë“œë°±**: {evaluation['feedback']}\n\n"
        
        if evaluation.get('recommended_review'):
            result += f"**ë³µìŠµ ì¶”ì²œ**: {', '.join(evaluation['recommended_review'])}\n"
        
        avg_score = sum(state.score_history) / len(state.score_history) if state.score_history else 0
        stats = f"í‰ê·  ì ìˆ˜: {avg_score:.1f} | ì´ {len(state.score_history)}ë¬¸ì œ"
        
        return result, feedback_audio, stats
    
    def upload_course_materials(files):
        """ìˆ˜ì—…ìë£Œ ì—…ë¡œë“œ ë° ì²˜ë¦¬"""
        if not files:
            return "âŒ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”."
        
        try:
            file_paths = [f.name for f in files]
            result = simulator.doc_processor.process_course_materials(file_paths)
            
            summary = f"### âœ… ìˆ˜ì—…ìë£Œ ì²˜ë¦¬ ì™„ë£Œ\n\n"
            summary += f"- íŒŒì¼: {result['files_processed']}ê°œ\n"
            summary += f"- ì¶”ì¶œëœ ì²­í¬: {result['chunks_extracted']}ê°œ\n"
            summary += f"- ì§€ì‹ í•­ëª©: {result['knowledge_items']}ê°œ\n"
            summary += f"- ìƒì„±ëœ ì§ˆë¬¸: {result['questions_generated']}ê°œ\n"
            summary += f"- ì—…ë¡œë“œ ì„±ê³µ: {result['upload_result']['success']}ê°œ\n\n"
            summary += "ì´ì œ ìƒì„±ëœ ì§ˆë¬¸ì„ í•™ìŠµ/ë©´ì ‘ ëª¨ë“œì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!"
            
            return summary
        
        except Exception as e:
            return f"âŒ ì˜¤ë¥˜: {str(e)}"
    
    # === Gradio UI ===
    
    with gr.Blocks(title="ë°˜ë„ì²´ ê³µì • í•™ìŠµ & ë©´ì ‘ ì‹œë®¬ë ˆì´í„°", theme=gr.themes.Soft()) as demo:
        gr.Markdown("""
        # âš¡ ë°˜ë„ì²´ ê³µì • í•™ìŠµ & ë©´ì ‘ ì‹œë®¬ë ˆì´í„°
        ### í•™ë¶€ìƒì„ ìœ„í•œ ë§ì¶¤í˜• í•™ìŠµ ë° ë©´ì ‘ ì¤€ë¹„ í”Œë«í¼
        
        **ì£¼ìš” ê¸°ëŠ¥**:
        - ğŸ“š ìˆ˜ì—…ìë£Œ ê¸°ë°˜ RAG í•™ìŠµ ì‹œìŠ¤í…œ
        - ğŸ¯ ì´ë ¥ì„œ/ìì†Œì„œ ë¶„ì„ì„ í†µí•œ ë§ì¶¤í˜• ë©´ì ‘
        - ğŸ”Š Custom Voiceë¡œ ì‹¤ê°ë‚˜ëŠ” ì‹œë®¬ë ˆì´ì…˜
        - ğŸ“Š ìƒì„¸í•œ ë‹µë³€ í‰ê°€ ë° í”¼ë“œë°±
        """)
        
        with gr.Tabs():
            # === íƒ­ 1: í”„ë¡œí•„ ì„¤ì • ===
            with gr.Tab("ğŸ‘¤ í”„ë¡œí•„ ì„¤ì •"):
                gr.Markdown("""
                ## ê°œì¸ ë§ì¶¤í˜• í•™ìŠµì„ ìœ„í•œ í”„ë¡œí•„ ì„¤ì •
                ì´ë ¥ì„œì™€ ìê¸°ì†Œê°œì„œë¥¼ ì—…ë¡œë“œí•˜ë©´ ë§ì¶¤í˜• ì§ˆë¬¸ì„ ìƒì„±í•©ë‹ˆë‹¤.
                """)
                
                with gr.Row():
                    resume_upload = gr.File(
                        label="ì´ë ¥ì„œ (PDF/DOCX)",
                        file_types=[".pdf", ".docx"]
                    )
                    statement_upload = gr.File(
                        label="ìê¸°ì†Œê°œì„œ (PDF/DOCX)",
                        file_types=[".pdf", ".docx"]
                    )
                
                analyze_btn = gr.Button("ë¶„ì„ ì‹œì‘", variant="primary", size="lg")
                
                profile_result = gr.Markdown()
                profile_status = gr.Textbox(label="ìƒíƒœ", interactive=False)
                
                analyze_btn.click(
                    fn=upload_and_analyze_documents,
                    inputs=[resume_upload, statement_upload],
                    outputs=[profile_result, profile_status]
                )
            
            # === íƒ­ 2: ìˆ˜ì—…ìë£Œ ì—…ë¡œë“œ ===
            with gr.Tab("ğŸ“– ìˆ˜ì—…ìë£Œ ê´€ë¦¬"):
                gr.Markdown("""
                ## ìˆ˜ì—…ìë£Œ ì—…ë¡œë“œ
                PDF, PPT, DOCX í˜•ì‹ì˜ ìˆ˜ì—…ìë£Œë¥¼ ì—…ë¡œë“œí•˜ë©´ ìë™ìœ¼ë¡œ ì§€ì‹ì„ ì¶”ì¶œí•˜ì—¬ RAG DBë¥¼ êµ¬ì¶•í•©ë‹ˆë‹¤.
                """)
                
                course_files = gr.File(
                    label="ìˆ˜ì—…ìë£Œ íŒŒì¼ (ì—¬ëŸ¬ ê°œ ê°€ëŠ¥)",
                    file_count="multiple",
                    file_types=[".pdf", ".pptx", ".docx"]
                )
                
                process_btn = gr.Button("ìë£Œ ì²˜ë¦¬ ì‹œì‘", variant="primary")
                process_result = gr.Markdown()
                
                process_btn.click(
                    fn=upload_course_materials,
                    inputs=[course_files],
                    outputs=[process_result]
                )
            
            # === íƒ­ 3: í•™ìŠµ ëª¨ë“œ ===
            with gr.Tab("ğŸ“š í•™ìŠµ ëª¨ë“œ"):
                gr.Markdown("""
                ## ê°œë… í•™ìŠµ ë° ì´ë¡  ë³µìŠµ
                ì£¼ì œë¥¼ ì„ íƒí•˜ê³  ë‚œì´ë„ë³„ í•™ìŠµ ì§ˆë¬¸ì„ í’€ì–´ë³´ì„¸ìš”.
                """)
                
                with gr.Row():
                    with gr.Column():
                        study_topic = gr.Textbox(
                            label="í•™ìŠµ ì£¼ì œ",
                            placeholder="ì˜ˆ: CVD ì¦ì°© ê³µì •, í”Œë¼ì¦ˆë§ˆ ì‹ê°, í¬í† ë¦¬ì†Œê·¸ë˜í”¼",
                            value="CVD ì¦ì°©"
                        )
                        study_difficulty = gr.Radio(
                            choices=["ê¸°ì´ˆ", "ì¤‘ê¸‰", "ê³ ê¸‰"],
                            label="ë‚œì´ë„",
                            value="ì¤‘ê¸‰"
                        )
                        study_type = gr.Radio(
                            choices=["ê°œë…ì´í•´", "ì›ë¦¬ì„¤ëª…", "ì‘ìš©", "ë¹„êµ", "ì‹¤ë¬´"],
                            label="ì§ˆë¬¸ ìœ í˜•",
                            value="ê°œë…ì´í•´"
                        )
                        study_start_btn = gr.Button("ì§ˆë¬¸ ë°›ê¸° ğŸ“", variant="primary")
                    
                    with gr.Column():
                        study_question = gr.Markdown()
                        study_audio = gr.Audio(label="ì§ˆë¬¸ ìŒì„±")
                
                gr.Markdown("---")
                
                with gr.Row():
                    with gr.Column():
                        study_answer_audio = gr.Audio(
                            sources=["microphone"],
                            type="filepath",
                            label="ìŒì„± ë‹µë³€"
                        )
                        study_answer_text = gr.Textbox(
                            label="í…ìŠ¤íŠ¸ ë‹µë³€",
                            lines=5,
                            placeholder="ë‹µë³€ì„ ì…ë ¥í•˜ì„¸ìš”..."
                        )
                        study_submit_btn = gr.Button("ë‹µë³€ ì œì¶œ", variant="primary")
                    
                    with gr.Column():
                        study_evaluation = gr.Markdown()
                        study_feedback_audio = gr.Audio(label="í”¼ë“œë°± ìŒì„±")
                        study_stats = gr.Textbox(label="í•™ìŠµ í†µê³„", interactive=False)
                
                study_start_btn.click(
                    fn=start_study_mode,
                    inputs=[study_topic, study_difficulty, study_type],
                    outputs=[study_question, study_audio]
                )
                
                study_submit_btn.click(
                    fn=submit_answer,
                    inputs=[study_answer_audio, study_answer_text],
                    outputs=[study_evaluation, study_feedback_audio, study_stats]
                )
            
            # === íƒ­ 4: ë©´ì ‘ ëª¨ë“œ ===
            with gr.Tab("ğŸ¯ ë©´ì ‘ ëª¨ë“œ"):
                gr.Markdown("""
                ## ì‹¤ì „ ë©´ì ‘ ì‹œë®¬ë ˆì´ì…˜
                ë°˜ë„ì²´ ê¸°ì—… ë©´ì ‘ì„ ëŒ€ë¹„í•œ ì‹¤ì „ ì—°ìŠµ
                """)
                
                with gr.Row():
                    with gr.Column():
                        interview_focus = gr.Textbox(
                            label="ì¤‘ì  ë¶„ì•¼ (ì„ íƒì‚¬í•­)",
                            placeholder="ì˜ˆ: ì¦ì°© ê³µì •, ë°•ë§‰ ë¶„ì„, ê³µì • ìµœì í™”",
                            value=""
                        )
                        interview_use_profile = gr.Checkbox(
                            label="ë‚´ í”„ë¡œí•„ ê¸°ë°˜ ë§ì¶¤í˜• ì§ˆë¬¸",
                            value=True
                        )
                        interview_start_btn = gr.Button("ë©´ì ‘ ì‹œì‘ ğŸš€", variant="primary")
                    
                    with gr.Column():
                        interview_question = gr.Markdown()
                        interview_audio = gr.Audio(label="ë©´ì ‘ê´€ ìŒì„± (Custom Voice)")
                
                gr.Markdown("---")
                
                with gr.Row():
                    with gr.Column():
                        interview_answer_audio = gr.Audio(
                            sources=["microphone"],
                            type="filepath",
                            label="ìŒì„± ë‹µë³€"
                        )
                        interview_answer_text = gr.Textbox(
                            label="í…ìŠ¤íŠ¸ ë‹µë³€",
                            lines=5
                        )
                        interview_submit_btn = gr.Button("ë‹µë³€ ì œì¶œ", variant="primary")
                    
                    with gr.Column():
                        interview_evaluation = gr.Markdown()
                        interview_feedback_audio = gr.Audio(label="í”¼ë“œë°± ìŒì„±")
                        interview_stats = gr.Textbox(label="ë©´ì ‘ í†µê³„", interactive=False)
                
                interview_start_btn.click(
                    fn=start_interview_mode,
                    inputs=[interview_focus, interview_use_profile],
                    outputs=[interview_question, interview_audio]
                )
                
                interview_submit_btn.click(
                    fn=submit_answer,
                    inputs=[interview_answer_audio, interview_answer_text],
                    outputs=[interview_evaluation, interview_feedback_audio, interview_stats]
                )
    
    return demo


if __name__ == "__main__":
    demo = create_gradio_interface()
    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False
    )
