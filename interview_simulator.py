"""
Azure ê¸°ë°˜ ëª¨ì˜ ë©´ì ‘ ì‹œë®¬ë ˆì´ì…˜ ì‹œìŠ¤í…œ
- Custom Voiceë¡œ ë©´ì ‘ê´€ ìŒì„±
- RAG ê¸°ë°˜ ì§ˆë¬¸ ìƒì„±
- ì½”ë“œ ì‹¤í–‰ ë° ì´ë¯¸ì§€ ìƒì„± ê¸°ëŠ¥
"""

import os
import json
import base64
from io import BytesIO
from typing import List, Dict, Tuple
import gradio as gr
import azure.cognitiveservices.speech as speechsdk
from openai import AzureOpenAI
from azure.search.documents import SearchClient
from azure.search.documents.models import VectorizedQuery
from azure.core.credentials import AzureKeyCredential
from PIL import Image
import requests
import numpy as np

class InterviewSimulator:
    def __init__(self):
        # Azure Speech Service ì„¤ì •
        self.speech_key = os.getenv("AZURE_SPEECH_KEY")
        self.speech_region = os.getenv("AZURE_SPEECH_REGION")
        self.custom_voice_name = os.getenv("CUSTOM_VOICE_NAME")  # ì˜ˆ: "YourCustomVoice"
        
        # Azure OpenAI ì„¤ì •
        self.openai_client = AzureOpenAI(
            api_key=os.getenv("AZURE_OPENAI_KEY"),
            api_version="2024-02-15-preview",
            azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT")
        )
        self.gpt_deployment = os.getenv("GPT_DEPLOYMENT_NAME", "gpt-4")
        self.dalle_deployment = os.getenv("DALLE_DEPLOYMENT_NAME", "dall-e-3")
        
        # Azure AI Search ì„¤ì • (RAG)
        self.search_client = SearchClient(
            endpoint=os.getenv("AZURE_SEARCH_ENDPOINT"),
            index_name=os.getenv("AZURE_SEARCH_INDEX", "interview-questions"),
            credential=AzureKeyCredential(os.getenv("AZURE_SEARCH_KEY"))
        )
        
        # ëŒ€í™” íˆìŠ¤í† ë¦¬
        self.conversation_history = []
        self.current_question_context = None
        
    def initialize_speech_config(self):
        """Speech ì„¤ì • ì´ˆê¸°í™”"""
        speech_config = speechsdk.SpeechConfig(
            subscription=self.speech_key,
            region=self.speech_region
        )
        # Custom Voice ì„¤ì •
        speech_config.speech_synthesis_voice_name = self.custom_voice_name
        return speech_config
    
    def speech_to_text(self, audio_file) -> str:
        """ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ (STT)"""
        speech_config = speechsdk.SpeechConfig(
            subscription=self.speech_key,
            region=self.speech_region
        )
        speech_config.speech_recognition_language = "ko-KR"
        
        audio_config = speechsdk.audio.AudioConfig(filename=audio_file)
        speech_recognizer = speechsdk.SpeechRecognizer(
            speech_config=speech_config,
            audio_config=audio_config
        )
        
        result = speech_recognizer.recognize_once_async().get()
        
        if result.reason == speechsdk.ResultReason.RecognizedSpeech:
            return result.text
        else:
            return f"ìŒì„± ì¸ì‹ ì‹¤íŒ¨: {result.reason}"
    
    def text_to_speech(self, text: str, output_file: str = "output.wav"):
        """í…ìŠ¤íŠ¸ë¥¼ Custom Voiceë¡œ ìŒì„± ë³€í™˜ (TTS)"""
        speech_config = self.initialize_speech_config()
        audio_config = speechsdk.audio.AudioOutputConfig(filename=output_file)
        
        speech_synthesizer = speechsdk.SpeechSynthesizer(
            speech_config=speech_config,
            audio_config=audio_config
        )
        
        # SSMLì„ ì‚¬ìš©í•˜ì—¬ ë” ìì—°ìŠ¤ëŸ¬ìš´ ìŒì„± ìƒì„±
        ssml = f"""
        <speak version='1.0' xmlns='http://www.w3.org/2001/10/synthesis' xml:lang='ko-KR'>
            <voice name='{self.custom_voice_name}'>
                <prosody rate='0.95' pitch='0%'>
                    {text}
                </prosody>
            </voice>
        </speak>
        """
        
        result = speech_synthesizer.speak_ssml_async(ssml).get()
        
        if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:
            return output_file
        else:
            print(f"TTS ì‹¤íŒ¨: {result.reason}")
            return None
    
    def get_embedding(self, text: str) -> List[float]:
        """í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±"""
        response = self.openai_client.embeddings.create(
            model="text-embedding-ada-002",
            input=text
        )
        return response.data[0].embedding
    
    def search_interview_questions(self, query: str, top_k: int = 3) -> List[Dict]:
        """RAG: ë²¡í„° ê²€ìƒ‰ìœ¼ë¡œ ê´€ë ¨ ë©´ì ‘ ì§ˆë¬¸ ê²€ìƒ‰"""
        try:
            query_vector = self.get_embedding(query)
            vector_query = VectorizedQuery(
                vector=query_vector,
                k_nearest_neighbors=top_k,
                fields="contentVector"
            )
            
            results = self.search_client.search(
                search_text=query,
                vector_queries=[vector_query],
                select=["question", "category", "difficulty", "context", "sample_answer"],
                top=top_k
            )
            
            return [
                {
                    "question": doc["question"],
                    "category": doc.get("category", "ì¼ë°˜"),
                    "difficulty": doc.get("difficulty", "ì¤‘"),
                    "context": doc.get("context", ""),
                    "sample_answer": doc.get("sample_answer", "")
                }
                for doc in results
            ]
        except Exception as e:
            print(f"ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []
    
    def generate_code_visualization(self, code_description: str) -> str:
        """ì½”ë“œ ì‹¤í–‰ ë° ì‹œê°í™” ìƒì„±"""
        prompt = f"""
ë‹¤ìŒ ìš”êµ¬ì‚¬í•­ì— ë§ëŠ” Python ì½”ë“œë¥¼ ì‘ì„±í•˜ê³  ì‹¤í–‰í•˜ì—¬ ì‹œê°í™”ë¥¼ ìƒì„±í•˜ì„¸ìš”:
{code_description}

matplotlibë¥¼ ì‚¬ìš©í•˜ì—¬ ê·¸ë˜í”„ë¥¼ ìƒì„±í•˜ê³ , ì‹¤í–‰ ê°€ëŠ¥í•œ ì½”ë“œë§Œ ë°˜í™˜í•˜ì„¸ìš”.
"""
        
        response = self.openai_client.chat.completions.create(
            model=self.gpt_deployment,
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ë°ì´í„° ì‹œê°í™” ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7
        )
        
        return response.choices[0].message.content
    
    def generate_image(self, prompt: str) -> str:
        """DALL-Eë¡œ ì´ë¯¸ì§€ ìƒì„±"""
        try:
            result = self.openai_client.images.generate(
                model=self.dalle_deployment,
                prompt=prompt,
                n=1,
                size="1024x1024"
            )
            
            image_url = result.data[0].url
            return image_url
        except Exception as e:
            print(f"ì´ë¯¸ì§€ ìƒì„± ì˜¤ë¥˜: {e}")
            return None
    
    def generate_interview_question(
        self, 
        user_profile: str, 
        difficulty: str = "ì¤‘",
        use_visualization: bool = False
    ) -> Dict:
        """RAG ê¸°ë°˜ ë©´ì ‘ ì§ˆë¬¸ ìƒì„±"""
        # 1. RAGë¡œ ê´€ë ¨ ì§ˆë¬¸ ê²€ìƒ‰
        search_results = self.search_interview_questions(user_profile, top_k=3)
        
        # 2. ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ í™œìš©
        context = "\n\n".join([
            f"ì°¸ê³  ì§ˆë¬¸ {i+1}:\n"
            f"ì§ˆë¬¸: {q['question']}\n"
            f"ì¹´í…Œê³ ë¦¬: {q['category']}\n"
            f"ë§¥ë½: {q['context']}"
            for i, q in enumerate(search_results)
        ])
        
        # 3. GPT-4ë¡œ ë§ì¶¤í˜• ì§ˆë¬¸ ìƒì„±
        system_prompt = f"""
ë‹¹ì‹ ì€ ì „ë¬¸ ë©´ì ‘ê´€ì…ë‹ˆë‹¤. ì•„ë˜ ê²€ìƒ‰ëœ ì§ˆë¬¸ë“¤ì„ ì°¸ê³ í•˜ì—¬, ì§€ì›ìì—ê²Œ ì í•©í•œ ë©´ì ‘ ì§ˆë¬¸ì„ ìƒì„±í•˜ì„¸ìš”.

**ì¤‘ìš”**: ê²€ìƒ‰ëœ ì§ˆë¬¸ë“¤ì˜ ë§¥ë½ê³¼ ì˜ë„ë¥¼ ì°¸ê³ í•˜ë˜, ì§€ì›ìì˜ í”„ë¡œí•„ì— ë§ê²Œ ë³€í˜•í•˜ê±°ë‚˜ ìƒˆë¡œìš´ ì§ˆë¬¸ì„ ë§Œë“¤ì–´ì•¼ í•©ë‹ˆë‹¤.
ì ˆëŒ€ë¡œ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ê·¸ëŒ€ë¡œ ì¶œë ¥í•˜ì§€ ë§ˆì„¸ìš”. í• ë£¨ì‹œë„¤ì´ì…˜ì„ í”¼í•˜ê¸° ìœ„í•´ ë°˜ë“œì‹œ ì œê³µëœ ì»¨í…ìŠ¤íŠ¸ì— ê·¼ê±°í•´ì•¼ í•©ë‹ˆë‹¤.

ë‚œì´ë„: {difficulty}
ì‹œê°ìë£Œ ì‚¬ìš©: {"ì˜ˆ" if use_visualization else "ì•„ë‹ˆì˜¤"}

ê²€ìƒ‰ëœ ì°¸ê³  ì§ˆë¬¸ë“¤:
{context}
"""
        
        user_prompt = f"""
ì§€ì›ì í”„ë¡œí•„: {user_profile}

ìœ„ ì°¸ê³  ì§ˆë¬¸ë“¤ì„ ë°”íƒ•ìœ¼ë¡œ ì´ ì§€ì›ìì—ê²Œ ì í•©í•œ ë©´ì ‘ ì§ˆë¬¸ì„ ìƒì„±í•˜ì„¸ìš”.

{"ë§Œì•½ ì‹œê°ìë£Œê°€ í•„ìš”í•œ ì§ˆë¬¸ì´ë¼ë©´, ì–´ë–¤ ì‹œê°ìë£Œ(ì°¨íŠ¸, ì´ë¯¸ì§€ ë“±)ê°€ í•„ìš”í•œì§€ ëª…ì‹œí•˜ì„¸ìš”." if use_visualization else ""}

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ:
{{
    "question": "ë©´ì ‘ ì§ˆë¬¸",
    "category": "ì§ˆë¬¸ ì¹´í…Œê³ ë¦¬",
    "rationale": "ì´ ì§ˆë¬¸ì„ ì„ íƒí•œ ì´ìœ ",
    "visualization_needed": true/false,
    "visualization_description": "í•„ìš”í•œ ì‹œê°ìë£Œ ì„¤ëª… (ì„ íƒì‚¬í•­)"
}}
"""
        
        response = self.openai_client.chat.completions.create(
            model=self.gpt_deployment,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.7,
            response_format={"type": "json_object"}
        )
        
        question_data = json.loads(response.choices[0].message.content)
        
        # 4. ì‹œê°ìë£Œ ìƒì„± (í•„ìš”í•œ ê²½ìš°)
        visualization_url = None
        if use_visualization and question_data.get("visualization_needed"):
            viz_desc = question_data.get("visualization_description", "")
            # ì´ë¯¸ì§€ ìƒì„± ë˜ëŠ” ì°¨íŠ¸ ìƒì„±
            if "ì°¨íŠ¸" in viz_desc or "ê·¸ë˜í”„" in viz_desc:
                # ì½”ë“œ ì‹¤í–‰ì€ ì œí•œì ì´ë¯€ë¡œ ì´ë¯¸ì§€ë¡œ ëŒ€ì²´
                visualization_url = self.generate_image(
                    f"Professional business chart or graph: {viz_desc}"
                )
            else:
                visualization_url = self.generate_image(viz_desc)
        
        question_data["visualization_url"] = visualization_url
        question_data["search_context"] = search_results
        
        return question_data
    
    def evaluate_answer(self, question: str, answer: str, context: List[Dict]) -> Dict:
        """ë‹µë³€ í‰ê°€"""
        # ì°¸ê³  ë‹µë³€ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        reference_answers = "\n\n".join([
            f"ì°¸ê³  ë‹µë³€ ì˜ˆì‹œ {i+1}:\n{q['sample_answer']}"
            for i, q in enumerate(context) if q.get('sample_answer')
        ])
        
        prompt = f"""
ë©´ì ‘ ì§ˆë¬¸: {question}
ì§€ì›ì ë‹µë³€: {answer}

ì°¸ê³  ë‹µë³€ë“¤:
{reference_answers}

ìœ„ ì°¸ê³  ë‹µë³€ë“¤ì„ ê¸°ì¤€ìœ¼ë¡œ ì§€ì›ìì˜ ë‹µë³€ì„ í‰ê°€í•˜ì„¸ìš”.

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ:
{{
    "score": 0-100,
    "strengths": ["ê°•ì  1", "ê°•ì  2"],
    "weaknesses": ["ê°œì„ ì  1", "ê°œì„ ì  2"],
    "feedback": "êµ¬ì²´ì ì¸ í”¼ë“œë°±",
    "suggested_answer": "ë” ë‚˜ì€ ë‹µë³€ ì˜ˆì‹œ"
}}
"""
        
        response = self.openai_client.chat.completions.create(
            model=self.gpt_deployment,
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ë©´ì ‘ í‰ê°€ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            response_format={"type": "json_object"}
        )
        
        return json.loads(response.choices[0].message.content)


# Question Generator ì„í¬íŠ¸
from question_generator import QuestionGenerator

# Gradio ì¸í„°í˜ì´ìŠ¤ êµ¬ì„±
def create_gradio_interface():
    simulator = InterviewSimulator()
    question_gen = QuestionGenerator()
    
    # ì„¸ì…˜ ìƒíƒœ ê´€ë¦¬
    class SessionState:
        def __init__(self):
            self.current_question = None
            self.question_count = 0
            self.total_score = 0
            self.feedback_history = []
            self.question_requirements = None
            self.gen_conversation = []
    
    state = SessionState()
    
    def start_interview(profile, difficulty, use_viz):
        """ë©´ì ‘ ì‹œì‘"""
        state.current_question = simulator.generate_interview_question(
            profile, difficulty, use_viz
        )
        state.question_count += 1
        
        question_text = state.current_question["question"]
        
        # TTSë¡œ ìŒì„± ìƒì„±
        audio_file = f"question_{state.question_count}.wav"
        simulator.text_to_speech(question_text, audio_file)
        
        # ì‹œê°ìë£Œê°€ ìˆìœ¼ë©´ í‘œì‹œ
        viz_url = state.current_question.get("visualization_url")
        
        return (
            f"**ì§ˆë¬¸ {state.question_count}** (ì¹´í…Œê³ ë¦¬: {state.current_question['category']})\n\n"
            f"{question_text}\n\n"
            f"*ì„ íƒ ì´ìœ : {state.current_question['rationale']}*",
            audio_file,
            viz_url if viz_url else None
        )
    
    def process_answer(audio_input, text_input):
        """ë‹µë³€ ì²˜ë¦¬ ë° í‰ê°€"""
        # ìŒì„± ë˜ëŠ” í…ìŠ¤íŠ¸ ì…ë ¥ ì²˜ë¦¬
        if audio_input:
            answer_text = simulator.speech_to_text(audio_input)
        else:
            answer_text = text_input
        
        # ë‹µë³€ í‰ê°€
        evaluation = simulator.evaluate_answer(
            state.current_question["question"],
            answer_text,
            state.current_question["search_context"]
        )
        
        state.total_score += evaluation["score"]
        state.feedback_history.append(evaluation)
        
        # í”¼ë“œë°± ìŒì„± ìƒì„±
        feedback_text = f"""
í‰ê°€ ì ìˆ˜: {evaluation['score']}ì 

ê°•ì : {', '.join(evaluation['strengths'])}

ê°œì„ ì : {', '.join(evaluation['weaknesses'])}

í”¼ë“œë°±: {evaluation['feedback']}
"""
        
        feedback_audio = f"feedback_{state.question_count}.wav"
        simulator.text_to_speech(feedback_text, feedback_audio)
        
        return (
            f"**ë‹µë³€:** {answer_text}\n\n"
            f"**í‰ê°€ ê²°ê³¼**\n\n"
            f"ì ìˆ˜: **{evaluation['score']}/100**\n\n"
            f"**ê°•ì :**\n" + "\n".join([f"- {s}" for s in evaluation['strengths']]) + "\n\n"
            f"**ê°œì„ ì :**\n" + "\n".join([f"- {w}" for w in evaluation['weaknesses']]) + "\n\n"
            f"**í”¼ë“œë°±:**\n{evaluation['feedback']}\n\n"
            f"**ì œì•ˆ ë‹µë³€:**\n{evaluation['suggested_answer']}",
            feedback_audio,
            f"í˜„ì¬ê¹Œì§€ í‰ê·  ì ìˆ˜: {state.total_score / state.question_count:.1f}ì "
        )
    
    # === ì§ˆë¬¸ ìƒì„± ê´€ë ¨ í•¨ìˆ˜ ===
    
    def chat_generate_questions(user_message, chat_history):
        """ëŒ€í™”í˜• ì§ˆë¬¸ ìƒì„±"""
        result = question_gen.chat_for_requirements(user_message)
        
        bot_response = result['response']
        state.gen_conversation.append((user_message, bot_response))
        
        # ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ ì—¬ë¶€ í™•ì¸
        if result.get('is_complete'):
            state.question_requirements = result['collected_info']
            return (
                chat_history + [[user_message, bot_response]],
                "",
                True,  # ìƒì„± ë²„íŠ¼ í™œì„±í™”
                f"âœ… ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ! ì´ {result['collected_info'].get('question_count', 20)}ê°œ ì§ˆë¬¸ì„ ìƒì„±í•©ë‹ˆë‹¤."
            )
        else:
            return (
                chat_history + [[user_message, bot_response]],
                "",
                False,  # ìƒì„± ë²„íŠ¼ ë¹„í™œì„±í™”
                "ğŸ’¬ ëŒ€í™”ë¥¼ ê³„ì†í•˜ì„¸ìš”..."
            )
    
    def execute_question_generation():
        """ì‹¤ì œ ì§ˆë¬¸ ìƒì„± ë° ì—…ë¡œë“œ"""
        if not state.question_requirements:
            return "âŒ ë¨¼ì € ëŒ€í™”ë¥¼ í†µí•´ ìš”êµ¬ì‚¬í•­ì„ ìˆ˜ì§‘í•˜ì„¸ìš”.", ""
        
        try:
            # ì§ˆë¬¸ ìƒì„±
            questions = question_gen.generate_questions(state.question_requirements)
            
            # ë¯¸ë¦¬ë³´ê¸° í…ìŠ¤íŠ¸ ìƒì„±
            preview = f"### ìƒì„±ëœ ì§ˆë¬¸ ({len(questions)}ê°œ)\n\n"
            for i, q in enumerate(questions[:5], 1):
                preview += f"**{i}. [{q['difficulty']}] {q['category']}**\n"
                preview += f"{q['question']}\n\n"
            
            if len(questions) > 5:
                preview += f"... ì™¸ {len(questions) - 5}ê°œ ì§ˆë¬¸\n\n"
            
            # Azure AI Searchì— ì—…ë¡œë“œ
            upload_result = question_gen.upload_to_search(questions)
            
            result_msg = (
                f"### âœ… ì§ˆë¬¸ ìƒì„± ì™„ë£Œ!\n\n"
                f"- ìƒì„±: {len(questions)}ê°œ\n"
                f"- ì—…ë¡œë“œ ì„±ê³µ: {upload_result['success']}ê°œ\n"
                f"- ì—…ë¡œë“œ ì‹¤íŒ¨: {upload_result['failed']}ê°œ\n\n"
                f"ì´ì œ ë©´ì ‘ ì‹œì‘ íƒ­ì—ì„œ ìƒì„±ëœ ì§ˆë¬¸ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!"
            )
            
            return result_msg, preview
            
        except Exception as e:
            return f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", ""
    
    def analyze_question_db():
        """ì§ˆë¬¸ DB í˜„í™© ë¶„ì„"""
        stats = question_gen.analyze_existing_questions()
        
        if 'error' in stats:
            return f"âŒ ì˜¤ë¥˜: {stats['error']}"
        
        analysis = f"### ğŸ“Š ì§ˆë¬¸ DB í˜„í™©\n\n"
        analysis += f"**ì´ ì§ˆë¬¸ ìˆ˜**: {stats['total_questions']}ê°œ\n\n"
        
        if stats.get('by_category'):
            analysis += "**ì¹´í…Œê³ ë¦¬ë³„**:\n"
            for cat, count in stats['by_category'].items():
                analysis += f"- {cat}: {count}ê°œ\n"
            analysis += "\n"
        
        if stats.get('by_difficulty'):
            analysis += "**ë‚œì´ë„ë³„**:\n"
            for diff, count in stats['by_difficulty'].items():
                analysis += f"- {diff}: {count}ê°œ\n"
            analysis += "\n"
        
        if stats.get('by_position'):
            analysis += "**ì§ë¬´ë³„**:\n"
            for pos, count in sorted(stats['by_position'].items(), key=lambda x: x[1], reverse=True)[:10]:
                if pos:
                    analysis += f"- {pos}: {count}ê°œ\n"
        
        return analysis
    
    def generate_from_job_description(jd_text, num_questions):
        """ì§ë¬´ê¸°ìˆ ì„œ ê¸°ë°˜ ì§ˆë¬¸ ìƒì„±"""
        if not jd_text.strip():
            return "âŒ ì§ë¬´ê¸°ìˆ ì„œë¥¼ ì…ë ¥í•˜ì„¸ìš”.", ""
        
        try:
            questions = question_gen.generate_from_document(jd_text, num_questions)
            
            # ë¯¸ë¦¬ë³´ê¸°
            preview = f"### ìƒì„±ëœ ì§ˆë¬¸ ({len(questions)}ê°œ)\n\n"
            for i, q in enumerate(questions, 1):
                preview += f"**{i}. [{q.get('difficulty', 'ì¤‘')}] {q.get('category', '')}**\n"
                preview += f"{q['question']}\n"
                preview += f"*ì—°ê´€ì„±: {q.get('document_relevance', 'N/A')}*\n\n"
            
            # ì—…ë¡œë“œ
            upload_result = question_gen.upload_to_search(questions)
            
            result = (
                f"### âœ… ì§ˆë¬¸ ìƒì„± ì™„ë£Œ!\n\n"
                f"- ìƒì„±: {len(questions)}ê°œ\n"
                f"- ì—…ë¡œë“œ ì„±ê³µ: {upload_result['success']}ê°œ\n"
            )
            
            return result, preview
            
        except Exception as e:
            return f"âŒ ì˜¤ë¥˜: {str(e)}", ""
    
    # Gradio UI êµ¬ì„±
    with gr.Blocks(title="AI ëª¨ì˜ ë©´ì ‘ ì‹œë®¬ë ˆì´í„°", theme=gr.themes.Soft()) as demo:
        gr.Markdown("""
        # ğŸ¤ AI ëª¨ì˜ ë©´ì ‘ ì‹œë®¬ë ˆì´í„°
        ### Azure Custom Voice ê¸°ë°˜ ì‹¤ì „ ë©´ì ‘ ì—°ìŠµ
        
        **íŠ¹ì§•:**
        - âœ… ë‹¹ì‹ ì˜ ëª©ì†Œë¦¬ë¡œ ë©´ì ‘ê´€ ì—­í• 
        - âœ… RAG ê¸°ë°˜ ë§ì¶¤í˜• ì§ˆë¬¸ (í• ë£¨ì‹œë„¤ì´ì…˜ ë°©ì§€)
        - âœ… ëŒ€í™”í˜• ì§ˆë¬¸ ìë™ ìƒì„±
        - âœ… ì‹œê°ìë£Œ ì œê³µ (ì°¨íŠ¸, ì´ë¯¸ì§€)
        - âœ… ì‹¤ì‹œê°„ ë‹µë³€ í‰ê°€ ë° í”¼ë“œë°±
        """)
        
        with gr.Tabs():
            # ===== íƒ­ 1: ì§ˆë¬¸ ìë™ ìƒì„± =====
            with gr.Tab("ğŸ¤– ì§ˆë¬¸ ìë™ ìƒì„±"):
                gr.Markdown("""
                ## ëŒ€í™”í˜• ì§ˆë¬¸ ìƒì„±
                AIì™€ ëŒ€í™”í•˜ë©´ì„œ ì›í•˜ëŠ” ë©´ì ‘ ì§ˆë¬¸ì„ ìë™ìœ¼ë¡œ ìƒì„±í•˜ê³  DBì— ì¶”ê°€í•©ë‹ˆë‹¤.
                """)
                
                with gr.Row():
                    with gr.Column(scale=1):
                        gr.Markdown("### ğŸ’¬ AIì™€ ëŒ€í™”í•˜ê¸°")
                        gr.Markdown("""
                        **ì˜ˆì‹œ ì‹œì‘ ë©˜íŠ¸:**
                        - "Python ë°±ì—”ë“œ ê°œë°œì ë©´ì ‘ ì§ˆë¬¸ ë§Œë“¤ì–´ì¤˜"
                        - "5ë…„ì°¨ ë°ì´í„° ì‚¬ì´ì–¸í‹°ìŠ¤íŠ¸ ì§ˆë¬¸ ìƒì„±í•´ì¤˜"
                        - "React í”„ë¡ íŠ¸ì—”ë“œ ì‹ ì… ë©´ì ‘ ì¤€ë¹„ ì¤‘ì´ì•¼"
                        """)
                        
                        gen_chatbot = gr.Chatbot(
                            label="AI íë ˆì´í„°",
                            height=400
                        )
                        gen_input = gr.Textbox(
                            label="ë©”ì‹œì§€",
                            placeholder="ì–´ë–¤ ë©´ì ‘ ì§ˆë¬¸ì´ í•„ìš”í•˜ì‹ ê°€ìš”?",
                            lines=2
                        )
                        gen_send_btn = gr.Button("ì „ì†¡", variant="primary")
                        gen_status = gr.Textbox(
                            label="ìƒíƒœ",
                            value="ğŸ’¬ ëŒ€í™”ë¥¼ ì‹œì‘í•˜ì„¸ìš”...",
                            interactive=False
                        )
                    
                    with gr.Column(scale=1):
                        gr.Markdown("### âš™ï¸ ìƒì„± ë° ê´€ë¦¬")
                        
                        gen_button = gr.Button(
                            "ğŸ“ ì§ˆë¬¸ ìƒì„± ì‹œì‘",
                            variant="primary",
                            size="lg",
                            interactive=False
                        )
                        gen_result = gr.Markdown()
                        gen_preview = gr.Markdown(label="ë¯¸ë¦¬ë³´ê¸°")
                        
                        gr.Markdown("---")
                        gr.Markdown("### ğŸ“Š ì§ˆë¬¸ DB í˜„í™©")
                        analyze_btn = gr.Button("í˜„í™© ë¶„ì„")
                        analyze_result = gr.Markdown()
                
                # ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬
                def send_and_update(msg, history):
                    return chat_generate_questions(msg, history)
                
                gen_send_btn.click(
                    fn=send_and_update,
                    inputs=[gen_input, gen_chatbot],
                    outputs=[gen_chatbot, gen_input, gen_button, gen_status]
                )
                
                gen_input.submit(
                    fn=send_and_update,
                    inputs=[gen_input, gen_chatbot],
                    outputs=[gen_chatbot, gen_input, gen_button, gen_status]
                )
                
                gen_button.click(
                    fn=execute_question_generation,
                    outputs=[gen_result, gen_preview]
                )
                
                analyze_btn.click(
                    fn=analyze_question_db,
                    outputs=[analyze_result]
                )
            
            # ===== íƒ­ 2: ì§ë¬´ê¸°ìˆ ì„œ ê¸°ë°˜ ìƒì„± =====
            with gr.Tab("ğŸ“„ ì§ë¬´ê¸°ìˆ ì„œ ë¶„ì„"):
                gr.Markdown("""
                ## ì§ë¬´ê¸°ìˆ ì„œ/ê³µê³  ê¸°ë°˜ ì§ˆë¬¸ ìƒì„±
                ì±„ìš© ê³µê³ ë‚˜ ì§ë¬´ê¸°ìˆ ì„œë¥¼ ë¶™ì—¬ë„£ìœ¼ë©´ ê´€ë ¨ ë©´ì ‘ ì§ˆë¬¸ì„ ìë™ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.
                """)
                
                with gr.Row():
                    with gr.Column():
                        jd_input = gr.Textbox(
                            label="ì§ë¬´ê¸°ìˆ ì„œ / ì±„ìš©ê³µê³ ",
                            placeholder="ì§ë¬´ê¸°ìˆ ì„œë‚˜ ì±„ìš©ê³µê³  ë‚´ìš©ì„ ë¶™ì—¬ë„£ìœ¼ì„¸ìš”...",
                            lines=15
                        )
                        jd_num = gr.Slider(
                            minimum=5,
                            maximum=30,
                            value=15,
                            step=1,
                            label="ìƒì„±í•  ì§ˆë¬¸ ê°œìˆ˜"
                        )
                        jd_btn = gr.Button("ì§ˆë¬¸ ìƒì„±", variant="primary")
                    
                    with gr.Column():
                        jd_result = gr.Markdown()
                        jd_preview = gr.Markdown()
                
                jd_btn.click(
                    fn=generate_from_job_description,
                    inputs=[jd_input, jd_num],
                    outputs=[jd_result, jd_preview]
                )
            
            # ===== íƒ­ 3: ë©´ì ‘ ì‹œì‘ =====
            with gr.Tab("ğŸ¯ ë©´ì ‘ ì‹œì‘"):
                with gr.Row():
                    with gr.Column(scale=1):
                        gr.Markdown("### ğŸ“‹ ë©´ì ‘ ì„¤ì •")
                        profile_input = gr.Textbox(
                            label="ì§€ì›ì í”„ë¡œí•„",
                            placeholder="ì˜ˆ: 3ë…„ì°¨ ë°±ì—”ë“œ ê°œë°œì, Python/Django ì „ë¬¸, AWS ê²½í—˜",
                            lines=3
                        )
                        difficulty_select = gr.Radio(
                            choices=["í•˜", "ì¤‘", "ìƒ"],
                            label="ë‚œì´ë„",
                            value="ì¤‘"
                        )
                        use_visualization = gr.Checkbox(
                            label="ì‹œê°ìë£Œ í™œìš©",
                            value=True
                        )
                        start_btn = gr.Button("ë©´ì ‘ ì‹œì‘ ğŸš€", variant="primary")
                    
                    with gr.Column(scale=2):
                        gr.Markdown("### ğŸ’¬ ë©´ì ‘ ì§„í–‰")
                        question_display = gr.Markdown()
                        question_audio = gr.Audio(label="ë©´ì ‘ê´€ ìŒì„± (Custom Voice)")
                        question_image = gr.Image(label="ì‹œê°ìë£Œ")
                
                gr.Markdown("---")
                
                with gr.Row():
                    with gr.Column():
                        gr.Markdown("### ğŸ™ï¸ ë‹µë³€í•˜ê¸°")
                        answer_audio = gr.Audio(
                            sources=["microphone"],
                            type="filepath",
                            label="ìŒì„±ìœ¼ë¡œ ë‹µë³€"
                        )
                        gr.Markdown("**ë˜ëŠ”**")
                        answer_text = gr.Textbox(
                            label="í…ìŠ¤íŠ¸ë¡œ ë‹µë³€",
                            placeholder="ë‹µë³€ì„ ì…ë ¥í•˜ì„¸ìš”...",
                            lines=5
                        )
                        submit_btn = gr.Button("ë‹µë³€ ì œì¶œ", variant="primary")
                    
                    with gr.Column():
                        gr.Markdown("### ğŸ“Š í‰ê°€ ê²°ê³¼")
                        evaluation_display = gr.Markdown()
                        feedback_audio = gr.Audio(label="í”¼ë“œë°± ìŒì„±")
                        score_display = gr.Textbox(label="ëˆ„ì  ì ìˆ˜", interactive=False)
                
                # ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬
                start_btn.click(
                    fn=start_interview,
                    inputs=[profile_input, difficulty_select, use_visualization],
                    outputs=[question_display, question_audio, question_image]
                )
                
                submit_btn.click(
                    fn=process_answer,
                    inputs=[answer_audio, answer_text],
                    outputs=[evaluation_display, feedback_audio, score_display]
                )
    
    return demo


if __name__ == "__main__":
    demo = create_gradio_interface()
    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=True
    )
